{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import shutil\n",
    "\n",
    "paths = ['continued/sensitive', 'general']\n",
    "os.makedirs('single_characters', exist_ok=True)\n",
    "\n",
    "i=0\n",
    "files = []\n",
    "for path in paths:\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.jpg'):\n",
    "            if file.replace('.jpg', '.txt') in os.listdir(path):\n",
    "                files.append(file.replace('.jpg', ''))\n",
    "\n",
    "        i+=1\n",
    "        print(i, end = '\\r')\n",
    "\n",
    "print(len(files))\n",
    "\n",
    "i = 0\n",
    "for path in paths:\n",
    "    for file in os.listdir(path):\n",
    "        if file.replace('.jpg', '').replace('.txt', '') in files:\n",
    "            shutil.copy(join(path, file), join('single_characters', file))\n",
    "\n",
    "        i+=1\n",
    "        print(i, end = '\\r')\n",
    "\n",
    "\n",
    "len(os.listdir('single_characters'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import shutil\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "path = 'single_characters'\n",
    "\n",
    "def contains_single_character(danbooru_string):\n",
    "    # Patterns indicating multiple characters\n",
    "    multiple_patterns = [\n",
    "        r'\\b\\+girls\\b',\n",
    "        r'\\b\\+boys\\b',\n",
    "        r'\\b\\+others\\b',\n",
    "        r'\\bmultiple girls\\b',\n",
    "        r'\\bmultiple boys\\b',\n",
    "        r'\\b\\d\\+girls\\b',\n",
    "        r'\\b\\d\\+boys\\b',           \n",
    "        r'\\b\\d\\+others\\b'\n",
    "        r'\\bgroup\\b',\n",
    "        r'\\bsiblings\\b',\n",
    "        r'\\bbrothers\\b',\n",
    "        r'\\bsisters\\b',\n",
    "        r'\\bbrothers and sisters\\b',\n",
    "    ]\n",
    "    \n",
    "    single_patterns = [\n",
    "        r'\\b1girl\\b',\n",
    "        r'\\b1boy\\b',\n",
    "        r'\\b1other\\b',\n",
    "        r'\\bsolo\\b',\n",
    "    ]\n",
    "\n",
    "    # Check for matches in multiple-character patterns\n",
    "    for pattern in multiple_patterns:\n",
    "        if re.search(pattern, danbooru_string):\n",
    "            return False\n",
    "        \n",
    "    # Count occurrences of \"1boy\" and \"1girl\"\n",
    "    single_counts = sum(bool(re.search(pattern, danbooru_string)) for pattern in single_patterns[:-1])  # Exclude \"solo\"\n",
    "    if single_counts > 1:  # If more than one single character term exists\n",
    "        return False\n",
    "\n",
    "    # If \"solo\" is present, treat as a single character\n",
    "    if re.search(r'\\bsolo\\b', danbooru_string):\n",
    "        return True\n",
    "\n",
    "    # Check for matches in single-character patterns\n",
    "    for pattern in single_patterns:\n",
    "        if re.search(pattern, danbooru_string):\n",
    "            return True\n",
    "\n",
    "   \n",
    "    return True\n",
    "\n",
    "single_files = {}\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i,file in enumerate(tqdm(os.listdir(path))):\n",
    "    if file.endswith('.txt'):\n",
    "        with open(join(path, file), 'r') as f:\n",
    "            content = f.read()\n",
    "        if contains_single_character(content):\n",
    "            single_files[file.replace('.txt', '')] = content\n",
    "            \n",
    "for file in tqdm(os.listdir(path)):\n",
    "    if file.split('.')[0] not in single_files.keys():\n",
    "        os.remove(os.path.join(path, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('single_characters'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some checks\n",
    "\n",
    "def has_only_one_number(string):\n",
    "    # Find all digits in the string\n",
    "    digits = re.findall(r'\\d', string)\n",
    "    # Check if there is exactly one digit\n",
    "    return len(digits) != 1\n",
    "\n",
    "# Process files to check for strings with only one number\n",
    "files_with_one_number = {}\n",
    "\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    if file.endswith('.txt'):\n",
    "        with open(join(path, file), 'r') as f:\n",
    "            content = f.read()\n",
    "        if has_only_one_number(content):\n",
    "            files_with_one_number[file.replace('.txt', '')] = content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fe862640a4443090694b23f44e3d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import re\n",
    "import json\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3.5-mini-instruct\", \n",
    "    device_map=\"cuda\", \n",
    "    torch_dtype=\"auto\", \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", padding_side = 'left')\n",
    "\n",
    "def get_json(text):\n",
    "    match = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group()\n",
    "        # Convert to JSON object to verify\n",
    "        json_data = json.loads(extracted_json)\n",
    "        return json_data\n",
    "    else:\n",
    "        print(\"No JSON found in the text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_string =\"1girl, kousaka kirino, ore no imouto ga konna ni kawaii wake ga nai, itou ryuusei, ||| sensitive, crossed legs, feet, kousaka kirino's school uniform, legs, long hair, no shoes, school uniform, serafuku, sitting, socks, solo, oldest, good quality, very aesthetic\"\n",
    "main_string = \"1girl, akiyama mio, k-on!, mifumi takafumi, ||| sensitive, animal ears, black eyes, black hair, cat ears, kneeling, long hair, sakuragaoka high school uniform, school uniform, shoes, solo, uwabaki, oldest, normal quality, very aesthetic\" \n",
    "# main_string = \"\"\"1girl, hirasawa yui, k-on!, shiou tsuyukusa, ||| sensitive, brown eyes, brown hair, checkered, don't say \"lazy\", dress, foreshortening, frills, guitar, hair ornament, instrument, pantyhose, short hair, solo, striped clothes, striped pantyhose, vertical-striped clothes, vertical-striped pantyhose, oldest, normal quality, very aesthetic\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful information extractor from danbooru strings\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"{example_string}\n",
    "\n",
    "            Can you get me the following attributes in JSON format from this danbooru. Make sure all the attributes are a string. Only output the json. All the values should be 1-2 words\n",
    "\n",
    "\n",
    "            Age\n",
    "            Gender\n",
    "            Ethnicity\n",
    "            Hair Style (Straight, Curly)\n",
    "            Hair Color \n",
    "            Hair Length (Short, Medium, Long)\n",
    "            Eye Color\n",
    "            Body Type (Athletic, Curvy, Thin)\n",
    "            Dress (Only the type should be mentioned)\"\"\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"{\n",
    "        \"Age\": \"Teen\",\n",
    "        \"Gender\": \"Female\",\n",
    "        \"Ethnicity\": \"Japanese\",\n",
    "        \"Hair Style\": \"Straight\",\n",
    "        \"Hair Color\": \"Blonde\",\n",
    "        \"Hair Length\": \"Long\",\n",
    "        \"Eye Color\": \"Blue\",\n",
    "        \"Body Type\": \"Slim\",\n",
    "        \"Dress\": \"Serafuku\"\n",
    "        }\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"{main_string}\n",
    "\n",
    "            Can you get me the following attributes in JSON format from this danbooru. Make sure all the attributes are a string. Only output the json. All the values should be 1-2 words\n",
    "\n",
    "\n",
    "            Age\n",
    "            Gender\n",
    "            Ethnicity\n",
    "            Hair Style (Straight, Curly)\n",
    "            Hair Color \n",
    "            Hair Length (Short, Medium, Long)\n",
    "            Eye Color\n",
    "            Body Type (Athletic, Curvy, Thin)\n",
    "            Dress (Only the type should be mentioned)\"\"\"},\n",
    "]\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 150,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/biplab/sarthak/miniconda3/envs/flsetup/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = pipe([messages], **generation_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated_text': ' {\\n        \"Age\": \"Teen\",\\n        \"Gender\": \"Female\",\\n        \"Ethnicity\": \"Japanese\",\\n        \"Hair Style\": \"Straight\",\\n        \"Hair Color\": \"Black\",\\n        \"Hair Length\": \"Long\",\\n        \"Eye Color\": \"Black\",\\n        \"Body Type\": \"Slim\",\\n        \"Dress\": \"School Uniform\"\\n        }\\n\\n\\nPlease note that the provided text does not contain explicit information about the age, ethnicity, hair style, hair color, eye color, and body type. Therefore, I have used the most likely assumptions based on the context'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 'Teen',\n",
       " 'Gender': 'Female',\n",
       " 'Ethnicity': 'Japanese',\n",
       " 'Hair Style': 'Straight',\n",
       " 'Hair Color': 'Black',\n",
       " 'Hair Length': 'Long',\n",
       " 'Eye Color': 'Black',\n",
       " 'Body Type': 'Slim',\n",
       " 'Dress': 'School Uniform'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json(output[0][0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting into a dataset for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data_list = []\n",
    "for chunk_idx in range(2):  # Assuming num_chunks is defined elsewhere\n",
    "    with open(f'generated_outputs_chunk_{chunk_idx}.jsonl', 'r') as file:\n",
    "        for l in file.readlines():\n",
    "            content = json.loads(l)\n",
    "            key = list(content.keys())[0]\n",
    "            value = content[key]\n",
    "            try:\n",
    "                data_list.append(pd.DataFrame(data = value, index=[key]))\n",
    "            except:\n",
    "                pass\n",
    "            # data_list.append(key)\n",
    "\n",
    "df = pd.concat(data_list)\n",
    "columns = list(df.columns)\n",
    "columns_lower = ['age', 'gender', 'ethnicity', 'hair style', 'hair color', 'hair length', 'eye color', 'body type', 'dress']\n",
    "df.drop(columns=[x for x in columns if x.lower() not in columns_lower], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Hair Style</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Hair Length</th>\n",
       "      <th>Eye Color</th>\n",
       "      <th>Body Type</th>\n",
       "      <th>Dress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>danbooru_1033555_1d84ae2b33b634b8cac9e6e9e8892a14.txt_0</th>\n",
       "      <td>Early</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Black</td>\n",
       "      <td>Long</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Slim</td>\n",
       "      <td>Sundress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danbooru_1033683_97ed963564accf59ed05a651151d5a12.txt_0</th>\n",
       "      <td>Early</td>\n",
       "      <td>Female</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Long</td>\n",
       "      <td>Black</td>\n",
       "      <td>Long</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Slim</td>\n",
       "      <td>Serafuku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danbooru_1079117_daf0cefc12ddc98f3309bf9b409c4934.txt_0</th>\n",
       "      <td>Early</td>\n",
       "      <td>Female</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Long</td>\n",
       "      <td>Black</td>\n",
       "      <td>Long</td>\n",
       "      <td>Black</td>\n",
       "      <td>Slim</td>\n",
       "      <td>School Uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danbooru_1079118_caaae512e97c073b8480451a4f4eeef4.txt_0</th>\n",
       "      <td>Early</td>\n",
       "      <td>Female</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Long</td>\n",
       "      <td>Black</td>\n",
       "      <td>Long</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Slim</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danbooru_1079184_5e964b47430f6c3eb0e335996482d975.txt_0</th>\n",
       "      <td>Early</td>\n",
       "      <td>Female</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Long</td>\n",
       "      <td>Black</td>\n",
       "      <td>Long</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Slim</td>\n",
       "      <td>School Uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Age  Gender Ethnicity  \\\n",
       "danbooru_1033555_1d84ae2b33b634b8cac9e6e9e8892a...  Early  Female   Unknown   \n",
       "danbooru_1033683_97ed963564accf59ed05a651151d5a...  Early  Female  Japanese   \n",
       "danbooru_1079117_daf0cefc12ddc98f3309bf9b409c49...  Early  Female  Japanese   \n",
       "danbooru_1079118_caaae512e97c073b8480451a4f4eee...  Early  Female  Japanese   \n",
       "danbooru_1079184_5e964b47430f6c3eb0e335996482d9...  Early  Female  Japanese   \n",
       "\n",
       "                                                   Hair Style Hair Color  \\\n",
       "danbooru_1033555_1d84ae2b33b634b8cac9e6e9e8892a...   Straight      Black   \n",
       "danbooru_1033683_97ed963564accf59ed05a651151d5a...       Long      Black   \n",
       "danbooru_1079117_daf0cefc12ddc98f3309bf9b409c49...       Long      Black   \n",
       "danbooru_1079118_caaae512e97c073b8480451a4f4eee...       Long      Black   \n",
       "danbooru_1079184_5e964b47430f6c3eb0e335996482d9...       Long      Black   \n",
       "\n",
       "                                                   Hair Length Eye Color  \\\n",
       "danbooru_1033555_1d84ae2b33b634b8cac9e6e9e8892a...        Long     Brown   \n",
       "danbooru_1033683_97ed963564accf59ed05a651151d5a...        Long     Brown   \n",
       "danbooru_1079117_daf0cefc12ddc98f3309bf9b409c49...        Long     Black   \n",
       "danbooru_1079118_caaae512e97c073b8480451a4f4eee...        Long      Blue   \n",
       "danbooru_1079184_5e964b47430f6c3eb0e335996482d9...        Long     Brown   \n",
       "\n",
       "                                                   Body Type           Dress  \n",
       "danbooru_1033555_1d84ae2b33b634b8cac9e6e9e8892a...      Slim        Sundress  \n",
       "danbooru_1033683_97ed963564accf59ed05a651151d5a...      Slim        Serafuku  \n",
       "danbooru_1079117_daf0cefc12ddc98f3309bf9b409c49...      Slim  School Uniform  \n",
       "danbooru_1079118_caaae512e97c073b8480451a4f4eee...      Slim            None  \n",
       "danbooru_1079184_5e964b47430f6c3eb0e335996482d9...      Slim  School Uniform  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts = {}\n",
    "for column in df.columns:\n",
    "    counts = df[column].value_counts()\n",
    "    # Remove values with a low count (e.g., less than 20)\n",
    "    counts = counts[counts >= 20]\n",
    "    unique_counts[column] = counts.to_dict()\n",
    "\n",
    "\n",
    "df_copy = df.copy()\n",
    "for column in unique_counts.keys():\n",
    "    df_copy = df_copy[df_copy[column].isin(unique_counts[column])]\n",
    "\n",
    "df = df_copy\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Hair Style</th>\n",
       "      <th>Hair Color</th>\n",
       "      <th>Hair Length</th>\n",
       "      <th>Eye Color</th>\n",
       "      <th>Body Type</th>\n",
       "      <th>Dress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danbooru_1329597_12e81cb275df88fcc46d80ccf9e20...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>danbooru_5846809_d40226fbdcd41f00ccc74d8f23efc...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>danbooru_2719090_f6240a50566c5bd0c596d23063a5c...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>danbooru_1204804_dfa27a941a4bc4d783ac80d4a3616...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>danbooru_2758066_02e53aeb7fb9e23ffb9bf112df714...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>danbooru_4344758_3d3205cb8e248e098a829c2bd3e61...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>danbooru_4201058_c0a285731616cc34c023d931d6662...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>danbooru_472675_9434e6644b6b71135942d0f749617e...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>danbooru_5817460_4fe517e056adfc20b6da19c39415e...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>danbooru_5131468_4d04da60c84ac281602401ad416c4...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2218 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  Age  Gender  \\\n",
       "0     danbooru_1329597_12e81cb275df88fcc46d80ccf9e20...    2       0   \n",
       "1     danbooru_5846809_d40226fbdcd41f00ccc74d8f23efc...    7       1   \n",
       "2     danbooru_2719090_f6240a50566c5bd0c596d23063a5c...    3       0   \n",
       "3     danbooru_1204804_dfa27a941a4bc4d783ac80d4a3616...    7       0   \n",
       "4     danbooru_2758066_02e53aeb7fb9e23ffb9bf112df714...    3       0   \n",
       "...                                                 ...  ...     ...   \n",
       "2213  danbooru_4344758_3d3205cb8e248e098a829c2bd3e61...    7       1   \n",
       "2214  danbooru_4201058_c0a285731616cc34c023d931d6662...    4       0   \n",
       "2215  danbooru_472675_9434e6644b6b71135942d0f749617e...    5       0   \n",
       "2216  danbooru_5817460_4fe517e056adfc20b6da19c39415e...    7       1   \n",
       "2217  danbooru_5131468_4d04da60c84ac281602401ad416c4...    7       1   \n",
       "\n",
       "      Ethnicity  Hair Style  Hair Color  Hair Length  Eye Color  Body Type  \\\n",
       "0             3           4           1            0          2          7   \n",
       "1             5          10           0            2          5          0   \n",
       "2             3           4           1            3          2          8   \n",
       "3             3           4           0            0         11          7   \n",
       "4             5           4           5            3          2          9   \n",
       "...         ...         ...         ...          ...        ...        ...   \n",
       "2213          3          10           1            2          2          7   \n",
       "2214          3           4           3            0          3          7   \n",
       "2215          3          12           3            0          3          4   \n",
       "2216          5           1           0            0          1          3   \n",
       "2217          5          10          10            2          2          8   \n",
       "\n",
       "      Dress  \n",
       "0        26  \n",
       "1        12  \n",
       "2        20  \n",
       "3        13  \n",
       "4        20  \n",
       "...     ...  \n",
       "2213     25  \n",
       "2214     23  \n",
       "2215     13  \n",
       "2216     18  \n",
       "2217     11  \n",
       "\n",
       "[2218 rows x 10 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {column: {value: idx for idx, value in enumerate(sorted(unique_counts[column].keys()))} for column in unique_counts.keys()}\n",
    "for column in encodings.keys():\n",
    "    df[column] = df[column].map(encodings[column])\n",
    "\n",
    "import json\n",
    "\n",
    "with open('encodings.json', 'w') as json_file:\n",
    "    json.dump(encodings, json_file)\n",
    "\n",
    "train_df = df.sample(frac=0.9, random_state=42)  # 80% for training\n",
    "test_df = df.drop(train_df.index)  # Remaining 20% for testing\n",
    "\n",
    "train_df.reset_index(inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flsetup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
